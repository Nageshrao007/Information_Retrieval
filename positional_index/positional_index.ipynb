{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe973ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "from nltk.stem import PorterStemmer as ps \n",
    "import nltk\n",
    "\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numbersorting(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "def remove_punc(data):\n",
    "    for p in \"!.,:@#$%^&?<>*()[}{]-=;/\\\"\\\\\\t\\n\":\n",
    "        if p in '\\n;?:!.,.':\n",
    "            data = data.replace(p,' ')\n",
    "        else: data = data.replace(p,'')\n",
    "    return data.lower()\n",
    "\n",
    "list_docs = []\n",
    "for file in sorted(glob.glob('file*.txt'),key = numbersorting):\n",
    "    with open(file,'r') as f:\n",
    "        if file not in list_docs:\n",
    "            list_docs.append(os.path.basename(file))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c679cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_index = {}\n",
    "newlist = []\n",
    "for i in range(len(list_docs)):\n",
    "    with open(list_docs[i]) as f:\n",
    "        doc = [a for a in remove_punc(f.read()).split(' ') if a != \"\"]\n",
    "        for idx, word in enumerate(doc):\n",
    "            stemmed = ps().stem(word)\n",
    "            if not stemmed in pos_index:\n",
    "                pos_index[stemmed] = [(i,idx)]\n",
    "            else: \n",
    "                pos_index[stemmed].append((i,idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8647b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('positionalindex.txt','w') as outfile:\n",
    "    json.dump(pos_index,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "787b30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('positionalindex.txt','r') as p:\n",
    "    positionalindex = json.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9ef713f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the words to search  :present in\n",
      "The given words are present in below files:\n",
      "['file_74.txt', 'file_112.txt', 'file_118.txt', 'file_204.txt', 'file_327.txt', 'file_404.txt', 'file_475.txt', 'file_492.txt', 'file_552.txt', 'file_554.txt', 'file_575.txt', 'file_590.txt', 'file_621.txt', 'file_657.txt', 'file_706.txt', 'file_838.txt', 'file_981.txt', 'file_1029.txt', 'file_1031.txt', 'file_1053.txt', 'file_1325.txt']\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "matches = []\n",
    "match = []\n",
    "res = []\n",
    "query = [a for a in input(\"enter the words to search  :\").lower().split(' ') if a != \"\"]\n",
    "word1, word2 = query\n",
    "word1 = ps().stem(remove_punc(word1).replace(' ',''))\n",
    "word2 = ps().stem(remove_punc(word2).replace(' ',''))\n",
    "for doc1, index1 in positionalindex[word1]:\n",
    "    for doc2, index2 in positionalindex[word2]:\n",
    "        if doc1 != doc2:\n",
    "            continue\n",
    "        if index1 == (index2 - 1):\n",
    "            matches.append( (doc1,index1) )\n",
    "            for i,j in matches:\n",
    "                match.append(i)\n",
    "            for i in match:\n",
    "                result.append((list_docs[i]))\n",
    "print(\"The given words are present in below files:\")\n",
    "for i in result:\n",
    "    if i not in res:\n",
    "        res.append(i)\n",
    "print(res)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c31b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass the above words as input to find the files in which they are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda3111",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stem = []\n",
    "with open(\"query.txt\") as f:\n",
    "    query = f.read()\n",
    "    toks = nltk.word_tokenize(query)\n",
    "    #print(query)\n",
    "    result = [' '.join(pair) for pair in zip(toks, toks[1:])]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a0484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(\"The size of index in bytes is : \")\n",
    "print(sys.getsizeof(positionalindex),'bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d92b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
