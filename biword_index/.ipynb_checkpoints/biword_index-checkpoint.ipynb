{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10cd5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b76e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers_from_filename(filename):\n",
    "    return re.search(r'\\d+', filename).group(0)\n",
    "def remove_punc(data):\n",
    "    for p in \"!.,:@#$%^&?<>*()[}{]-=;/\\\"\\\\\\t\\n\":\n",
    "        if p in '\\n;?:!.,.':\n",
    "            data = data.replace(p,' ')\n",
    "        else: data = data.replace(p,'')\n",
    "    return data.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d7eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist1 = {}\n",
    "for file in glob.glob('file*.txt'):\n",
    "    \n",
    "    with open(file,'r') as f:\n",
    "        \n",
    "        text = remove_punc(f.read())\n",
    "        file = numbers_from_filename(file)\n",
    "        toks = word_tokenize(text)\n",
    "        ps = PorterStemmer()\n",
    "        list_stem = [ps.stem(word) for word in toks]\n",
    "        result = [' '.join(pair) for pair in zip(list_stem, list_stem[1:])]\n",
    "        #print(result)\n",
    "        for j in result:\n",
    "            if j not in filelist1.keys():\n",
    "                filelist1[j] = {}\n",
    "                filelist1[j] = file\n",
    "            else:\n",
    "                filelist1[j] = filelist1[j] + \",\" + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"biword_index.json\", \"w\") as outfile:\n",
    "    json.dump(filelist1, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49be0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"biword_index.json\") as f:\n",
    "    x = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb97e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the input please enter words without stemming as input is stemmed in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f7bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer as ps\n",
    "\n",
    "result = []\n",
    "result1 = []\n",
    "matches = []\n",
    "match = []\n",
    "finalresult = set()\n",
    "no_of_inputs = input(\"enter no of inputs words(one or two)\")\n",
    "if no_of_inputs == 'one':\n",
    "    query = [a for a in input().lower().split(' ') if a != \"\"]\n",
    "    word1, word2 = query\n",
    "    word1 = ps().stem(remove_punc(word1).replace(' ',''))\n",
    "    word2 = ps().stem(remove_punc(word2).replace(' ',''))\n",
    "    word = word1 +' '+ word2\n",
    "    #print(word)\n",
    "    print()\n",
    "    print()\n",
    "    result = x.get(word,'Does not exits')\n",
    "    result = result.split(\",\")\n",
    "    result = set(result)\n",
    "    print(\"The given words are present in following files : \",result)\n",
    "else:\n",
    "    query = [a for a in input().lower().split(' ') if a != \"\"]\n",
    "    query2 = [a for a in input().lower().split(' ') if a != \"\"]\n",
    "    word1, word2 = query\n",
    "    word3, word4 = query2\n",
    "    word1 = ps().stem(remove_punc(word1).replace(' ',''))\n",
    "    word2 = ps().stem(remove_punc(word2).replace(' ',''))\n",
    "    word3 = ps().stem(remove_punc(word3).replace(' ',''))\n",
    "    word4 = ps().stem(remove_punc(word4).replace(' ',''))\n",
    "    word = word1 +' '+ word2\n",
    "    wordx = word3 +' '+ word4\n",
    "    #print(word)\n",
    "    print()\n",
    "    print()\n",
    "    result = x.get(word,'Does not exits')\n",
    "    result1 = x.get(wordx,'Does not exits')\n",
    "    #print(result)\n",
    "    #print(result1)\n",
    "    result = result.split(\",\")\n",
    "    result1 = result1.split(\",\")\n",
    "    result = set(result)\n",
    "    result1 = set(result1)\n",
    "    if input(\"enter (and ,or) to perform \") == 'and':\n",
    "        finalresult = result.intersection(result1)\n",
    "    else:\n",
    "        finalresult = result.union(result1)\n",
    "    print(\"The given words are present in following files : \",finalresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e730c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"query.txt\") as f:\n",
    "    query = f.read()\n",
    "    toks = word_tokenize(query)\n",
    "    result = [' '.join(pair) for pair in zip(toks, toks[1:])]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a551f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(\"The size of index in bytes is : \")\n",
    "print(sys.getsizeof(x),'bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfb9282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
